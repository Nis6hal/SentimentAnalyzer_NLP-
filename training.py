# -*- coding: utf-8 -*-
"""NLP Lab 8 Project Work.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Xfl6o8lO4pR4LDBSGBhhRIUKTuydygDS

**Lab 8: Project Work**
"""

import pickle
# Load the dataset
import numpy as np
import pandas as pd

df=pd.read_csv('samples.csv')
df.head()

#Check if any null values
df.isna().sum()

# if there is any nul value, drop it.
df = df.dropna()

import matplotlib.pyplot as plt
value_counts_target = df['Sentiment'].value_counts()
value_counts_target.plot(kind='bar')
plt.xlabel('Sentiment')
plt.ylabel('No of occurences ')
plt.title('Target Distribution .')
plt.show()

plt.pie(value_counts_target,labels=value_counts_target.index,autopct="%1.2f%%",colors=['blue','yellow','red','orange'])
plt.show()

import pandas as pd
import nltk
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score, classification_report

# Download NLTK data
nltk.download('stopwords')
from nltk.corpus import stopwords

# Preprocess the text data
stop_words = set(stopwords.words('english'))

#Create a preprocessing function
def preprocess_text(text):
    # Convert to lowercase
    text = text.lower()
    # Remove punctuation
    text = ''.join([char for char in text if char.isalnum() or char.isspace()])
    # Remove stopwords
    text = ' '.join([word for word in text.split() if word not in stop_words])
    return text

#Preprocess the sentences of dataset by using above function
df['Sentence'] = df['Sentence'].apply(preprocess_text)

# Vectorize the text data
vectorizer = CountVectorizer()
X = vectorizer.fit_transform(df['Sentence'])

# Split the dataset into training and testing sets at 80:20 ratio
X_train, X_test, y_train, y_test = train_test_split(X, df['Sentiment'], test_size=0.2, random_state=42)

X_train

# Train a Naive Bayes classifier
from sklearn import svm
classifier =svm.SVC()
classifier.fit(X_train, y_train)

# Make predictions
y_pred = classifier.predict(X_test)

# Evaluate the classifier
accuracy = accuracy_score(y_test, y_pred)
report = classification_report(y_test, y_pred)

print(f'Accuracy: {accuracy}')
print('Classification Report:')
print(report)

# Generate the confusion matrix

from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

conf_matrix = confusion_matrix(y_test, y_pred)

# Visualize the confusion matrix
plt.figure(figsize=(5, 4))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=classifier.classes_, yticklabels=classifier.classes_)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

def predict_sentiment(text):
    # Preprocess the text using the same function you defined earlier
    processed_text = preprocess_text(text)

    # Convert to vector using the same fitted vectorizer
    text_vector = vectorizer.transform([processed_text])

    # Predict sentiment using the trained classifier
    prediction = classifier.predict(text_vector)

    return prediction[0]

# Test the function with a single text
sample_text = "I am unhappy"
predicted_sentiment = predict_sentiment(sample_text)
print(f'The predicted sentiment for the sample text is: {predicted_sentiment}')

# Save trained model
with open("sentiment_model.pkl", "wb") as f:
    pickle.dump(classifier, f)

# Save fitted vectorizer
with open("vectorizer.pkl", "wb") as f:
    pickle.dump(vectorizer, f)
